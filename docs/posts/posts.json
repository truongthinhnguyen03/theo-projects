[
  {
    "path": "posts/2024-04-13-visualizing-oecd-data-on-vietnam-with-d3js/",
    "title": "Visualizing OECD Data on Vietnam with D3.js",
    "description": {},
    "author": [
      {
        "name": "Nguyen Truong Thinh",
        "url": {}
      }
    ],
    "date": "2024-04-13",
    "categories": [],
    "contents": "\r\nDistill is a publication format for scientific and technical writing, native to the web.\r\nLearn more about using Distill at https://rstudio.github.io/distill.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2024-04-13T22:48:31+07:00",
    "input_file": {}
  },
  {
    "path": "posts/2023-11-08-vietnam-household-living-standards-survey-data-cleaning-with-r/",
    "title": "Vietnam Household Living Standards Survey - Data Cleaning with R",
    "description": "Vietnam Household Living Standards Survey (VHLSS) is a nationwide-survey conducted by the General Statistics Office (GSO) to evaluate living standards for policy-making and socioeconomic development planning...",
    "author": [
      {
        "name": "Nguyen Truong Thinh",
        "url": {}
      }
    ],
    "date": "2023-11-08",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nIntroduction\r\nUnderstanding the data\r\nHow VHLSS is sampled\r\nData Cleaning\r\nImporting libraries\r\nDefining functions for data pre-processing\r\nConstructing h_code from HO1.dta files\r\nRemoving duplicates observations\r\nGet the common h_codes\r\nImporting .dta files and creating h_code variable\r\nConstruct panel_data\r\nPrint Panel data\r\n\r\n\r\nAcknowledgements\r\n\r\nIntroduction\r\nVietnam Household Living Standards Survey (VHLSS) is a nationwide-survey conducted by the General Statistics Office (GSO) to evaluate living standards for policy-making and socioeconomic development planning.\r\nFrom 2002 to 2010, this survey has been conducted regularly by the GSO every two years. From 2011 to 2020, VHLSS are conducted annually. However, the odd-numbered year surveys only collect data on demographics, employment and income.\r\nThis document outlines the process of data cleaning and preparation to construct a Panel dataset for further research projects.\r\nUnderstanding the data\r\nHow VHLSS is sampled\r\nAt the household level, each year, GSO with re-select 50% of surveyed households from previous year and the other 50% are newly selected. In other words, if in 2014, GSO surveyed 1,000 households, then in 2018, 500 from those will be re-selected for survey. GSO will select 500 new households for 2018 survey.\r\nFigure 1. Sample selection methods of VHLSS (Manual for Handing Resampled Microdata of VHLSS)Data Cleaning\r\nImporting libraries\r\n\r\n\r\n# Clear R environment: \r\nrm(list = ls())\r\n\r\n# Load some R packages: \r\nlibrary(dplyr)\r\nlibrary(stringr)\r\nlibrary(stringi)\r\nlibrary(kableExtra) # For presenting table. \r\nlibrary(haven)\r\nlibrary(rmarkdown)\r\n\r\n\r\nDefining functions for data pre-processing\r\nIn order to join VHLSS datasets from different years, we need to create hcode variable to join matching households. To do this, I will concatenate tinh, huyen, xa, diaban, hoso to create a 16-digit series.\r\n\r\n\r\nadd_zero <- function(var_name, n_max) {\r\n  \r\n  tibble(x_text = as.character(var_name)) %>% \r\n    mutate(n_digits = str_count(x_text),\r\n           delta = n_max - n_digits, \r\n           pre = strrep(\"0\", times = delta), \r\n           full_code = str_c(pre, x_text)) %>% \r\n    pull(full_code) %>% \r\n    return()\r\n}\r\n\r\ncreate_hcode <- function(data, year) {\r\n  data %>%\r\n    mutate(tinh_n = add_zero(tinh, 2),\r\n           huyen_n = add_zero(huyen, 3),\r\n           xa_n = add_zero(xa, 5),\r\n           diaban_n = add_zero(diaban, 3),\r\n           hoso_n = add_zero(hoso, 3)) %>%\r\n    mutate(h_code = str_c(tinh_n, huyen_n, xa_n, diaban_n, hoso_n)) %>%\r\n    mutate(year = year) %>% \r\n    select(-c(tinh_n, huyen_n, xa_n, diaban_n, hoso_n)) %>% \r\n    return()\r\n}\r\n\r\n\r\nConstructing h_code from HO1.dta files\r\n\r\n\r\n# HO1.dta:\r\nread_dta(\"./VHLSS2018/HO1.dta\") -> ho1_2018\r\nread_dta(\"./VHLSS2016/Ho1.dta\") -> ho1_2016\r\nread_dta(\"./VHLSS2014/Ho1.dta\") -> ho1_2014\r\nread_dta(\"./VHLSS2012/ho11.dta\") -> ho1_2012\r\nread_dta(\"./VHLSS2010/ho11.dta\") -> ho1_2010\r\n\r\nho1_2018 %>% \r\n  create_hcode(2018) %>%\r\n  mutate(h_code16 = str_c(add_zero(tinh16, 2), \r\n                          add_zero(huyen16, 3), \r\n                          add_zero(xa16, 5), \r\n                          add_zero(diaban16, 3), \r\n                          add_zero(hoso16, 3))) -> ho1_2018\r\n\r\nho1_2016 %>% \r\n  create_hcode(2016) %>%\r\n  mutate(h_code14 = str_c(add_zero(tinh14, 2), \r\n                          add_zero(huyen14, 3), \r\n                          add_zero(xa14, 5), \r\n                          add_zero(diaban14, 3), \r\n                          add_zero(hoso14, 3))) -> ho1_2016\r\n\r\nho1_2014 %>% \r\n  create_hcode(2014) %>%\r\n  mutate(h_code12 = str_c(add_zero(tinh12, 2), \r\n                          add_zero(huyen12, 3), \r\n                          add_zero(xa12, 5), \r\n                          add_zero(diaban12, 3), \r\n                          add_zero(hoso12, 3))) -> ho1_2014\r\n\r\nho1_2012 %>% \r\n  create_hcode(2012) %>%\r\n  mutate(h_code10 = str_c(add_zero(tinh2010, 2), \r\n                          add_zero(huyen2010, 3), \r\n                          add_zero(xa2010, 5), \r\n                          add_zero(diaban2010, 3), \r\n                          add_zero(hoso2010, 3))) -> ho1_2012\r\n\r\nho1_2010 %>% \r\n  create_hcode(2010) -> ho1_2010\r\n\r\n\r\nRemoving duplicates observations\r\nI’ve noticed there are duplicated observations in the datasets. Let’s remove those.\r\n\r\n\r\nremove_duplicates <- function(df) {\r\n  # Count the number of rows before removing duplicates\r\n  original_rows <- nrow(df)\r\n  \r\n  # Remove duplicates\r\n  df_unique <- df[!duplicated(df), ]\r\n  \r\n  # Count the number of rows after removing duplicates\r\n  new_rows <- nrow(df_unique)\r\n  \r\n  # Print the number of rows dropped\r\n  rows_dropped <- original_rows - new_rows\r\n  cat(\"Number of duplicate rows in\", deparse(substitute(df)), \"dropped:\", rows_dropped, \"\\n\")\r\n  \r\n  # Return the data frame with duplicates removed\r\n  return(df_unique)\r\n}\r\n\r\nremove_duplicates(ho1_2018) -> ho1_2018\r\n\r\nNumber of duplicate rows in ho1_2018 dropped: 165 \r\n\r\nremove_duplicates(ho1_2016) -> ho1_2016\r\n\r\nNumber of duplicate rows in ho1_2016 dropped: 0 \r\n\r\nremove_duplicates(ho1_2014) -> ho1_2014\r\n\r\nNumber of duplicate rows in ho1_2014 dropped: 0 \r\n\r\nremove_duplicates(ho1_2012) -> ho1_2012\r\n\r\nNumber of duplicate rows in ho1_2012 dropped: 0 \r\n\r\nremove_duplicates(ho1_2010) -> ho1_2010\r\n\r\nNumber of duplicate rows in ho1_2010 dropped: 0 \r\n\r\nGet the common h_codes\r\nFor each year, we have 2 variables h_code and h_code* (corresponding h_code of that household in the previous year). In order to create a panel dataset, we use the h_code* of a dataset to match with the h_code of the dataset from previous year.\r\nFor example, to join VHLSS 2018 & 2016, we use inner_join by h_code16 in VHLSS2018 = h_code in VHLSS2016.\r\nFigure 2. Joining datasets\r\n\r\nget_common_code <- function(df1, df2, h_code_prev) {\r\n  df1 %>% \r\n    select(all_of(c(\"h_code\", h_code_prev))) -> code_df1\r\n  df2 %>% \r\n    select(all_of(c(\"h_code\"))) -> code_df2\r\n  \r\n  join_vector <- c(\"h_code\")\r\n  names(join_vector) <- h_code_prev\r\n\r\n  code_df1 %>% \r\n    inner_join(code_df2, by = join_vector, keep=FALSE) %>% \r\n    pull(h_code) %>% \r\n    return()\r\n}\r\n\r\ncommon_code1816 <- get_common_code(ho1_2018, ho1_2016, \"h_code16\")\r\ncommon_code1614 <- get_common_code(ho1_2016, ho1_2014, \"h_code14\")\r\ncommon_code1412 <- get_common_code(ho1_2014, ho1_2012, \"h_code12\")\r\ncommon_code1210 <- get_common_code(ho1_2012, ho1_2010, \"h_code10\")\r\n\r\n\r\nImporting .dta files and creating h_code variable\r\n\r\n\r\nread_dta(\"./VHLSS2018/HO3.dta\") %>% \r\n  create_hcode(2018) -> ho3_2018\r\nread_dta(\"./VHLSS2016/Ho3.dta\") %>% \r\n  create_hcode(2016) -> ho3_2016\r\nread_dta(\"./VHLSS2014/Ho3.dta\") %>% \r\n  create_hcode(2014) -> ho3_2014\r\nread_dta(\"./VHLSS2012/ho13.dta\") %>% \r\n  create_hcode(2012) -> ho3_2012\r\nread_dta(\"./VHLSS2010/ho13.dta\") %>% \r\n  create_hcode(2010) -> ho3_2010\r\n\r\n\r\nConstruct panel_data\r\n\r\n\r\n# Select variables for analysis: \r\nvar_list <- c(\"h_code\", \"thunhap\", \"thubq\", \"year\")\r\n\r\n# Subsetting the datasets:\r\nho3_2018 %>% \r\n  filter(h_code %in% common_code1816) %>% \r\n  select(all_of(var_list)) -> ho3_2018_mini\r\n\r\nho3_2016 %>% \r\n  filter(h_code %in% common_code1816 | h_code %in% common_code1614) %>% \r\n  select(all_of(var_list)) -> ho3_2016_mini\r\n\r\nho3_2014 %>% \r\n  filter(h_code %in% common_code1614 | h_code %in% common_code1412) %>% \r\n  select(all_of(var_list)) -> ho3_2014_mini\r\n\r\nho3_2012 %>% \r\n  filter(h_code %in% common_code1412 | h_code %in% common_code1210) %>% \r\n  select(all_of(var_list)) -> ho3_2012_mini\r\n\r\nho3_2010 %>% \r\n  filter(h_code %in% common_code1210) %>% \r\n  select(all_of(var_list)) -> ho3_2010_mini\r\n\r\n# Join the datasets: \r\nbind_rows(ho3_2018_mini, ho3_2016_mini, ho3_2014_mini, ho3_2012_mini, ho3_2010_mini) -> pdata\r\nremove(ho3_2018_mini, ho3_2016_mini, ho3_2014_mini, ho3_2012_mini, ho3_2010_mini)\r\n\r\n\r\nPrint Panel data\r\n\r\n\r\npdata %>%\r\n  paged_table()\r\n\r\n\r\n\r\n\r\nFigure 3. Panel data\r\n\r\n\r\npdata %>% \r\n  count(year) %>%\r\n  paged_table()\r\n\r\n\r\n\r\n\r\nFigure 4. Unbalanced panel data\r\nAcknowledgements\r\nI extend my gratitude to Dr. Ha Thi Cam Van for introducing the Vietnam Household Living Standards Survey dataset to me and help me initiated this project. Special thanks to Mr. Nguyen Chi Dung for his insightful work on Prepare Panel Data for Econometric Analysis from VHLSS. His work served as an invaluable resource, guiding and enlightening my approach to data analysis in R.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2024-04-14T23:00:31+07:00",
    "input_file": "vietnam-household-living-standards-survey-data-cleaning-with-r.knit.md"
  },
  {
    "path": "posts/2020-11-18-people-with-disabilities-in-asean-countries/",
    "title": "On People with Disabilities across ASEAN countries",
    "description": "I gathered publicly available data on people with disabilities across ASEAN countries to reveal their economic barriers as well as potential.",
    "author": [
      {
        "name": "Nguyen Truong Thinh",
        "url": {}
      }
    ],
    "date": "2020-11-18",
    "categories": [],
    "contents": "\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2024-04-14T23:01:07+07:00",
    "input_file": "people-with-disabilities-in-asean-countries.knit.md"
  }
]
